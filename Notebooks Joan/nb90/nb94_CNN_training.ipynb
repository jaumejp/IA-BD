{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5f8724-c96d-42df-88e1-3b6256e7d1bb",
   "metadata": {},
   "source": [
    "### CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314510f3-5d79-41ff-b5ef-477bdea3ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be390b-fa6a-420c-93d6-6e439152970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84115ec8-5b5d-4c34-b7c1-55138b2304b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags, ImageOps, ImageDraw\n",
    "from src import bbox2tlbr, sqrbbox, compute_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e881a5",
   "metadata": {},
   "source": [
    "### 1. Dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_imgRoot = '../projects/ma24/data/test/images/'\n",
    "_classes = ['aegypti', 'albopictus', 'anopheles', 'culex', 'culiseta', 'japonicus-koreicus', '??']\n",
    "_imgSize = 512 # pretrained at 384\n",
    "_imgNorm = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "# control image max-size \n",
    "Image.MAX_IMAGE_PIXELS = 201326592\n",
    "Image.warnings.simplefilter('error', Image.DecompressionBombWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csvDataFile):\n",
    "        \n",
    "        self.df = pd.read_csv(csvDataFile)\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.Resize((_imgSize, _imgSize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(_imgNorm[0], _imgNorm[1])\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        # open image file\n",
    "        row = self.df.iloc[idx]\n",
    "        pilImg = Image.open('%s/%s' %(_imgRoot, row.img_fName))\n",
    "        # crop image\n",
    "        bbox = sqrbbox([(row.bbx_xtl, row.bbx_ytl), (row.bbx_xbr, row.bbx_ybr)], pilImg.size)\n",
    "        pilImg = pilImg.crop(bbox)\n",
    "        # transform to torch tensor image\n",
    "        torchImg = self.transform(pilImg)\n",
    "\n",
    "        return {'img_fName': row.img_fName, 'image' : torchImg, 'label': [_classes.index(row.class_label)]}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45db0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our custom dataset\n",
    "csvDataFile = '../projects/ma24/data/test/phase2_test.csv'\n",
    "_maDataset = maDataset(csvDataFile)\n",
    "_maDataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06dda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the dataloader\n",
    "batch_size, num_workers = 4, 8\n",
    "_dataLoader = DataLoader(_maDataset, batch_size = batch_size, shuffle = True, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008a3fd",
   "metadata": {},
   "source": [
    "### 2. Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad9ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = timm.create_model(\n",
    "        'tf_efficientnetv2_s',\n",
    "        pretrained = True,\n",
    "        num_classes = len(_classes),\n",
    "        global_pool = 'avg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c6969",
   "metadata": {},
   "source": [
    "### 3. Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00c0dd",
   "metadata": {},
   "source": [
    "#### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a63de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b6341e",
   "metadata": {},
   "source": [
    "#### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lRate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr = lRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d17ba",
   "metadata": {},
   "source": [
    "#### scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.995\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a18c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d88551",
   "metadata": {},
   "source": [
    "### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00df380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train\n",
    "try:\n",
    "    \n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    train_loss, train_match = .0, .0\n",
    "\n",
    "    max_epochs = 2\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "        for batch in _dataLoader:\n",
    "\n",
    "            # +++ forward pass\n",
    "            optimizer.zero_grad()\n",
    "            inputs = batch['image'].to(_device)\n",
    "            output = model(inputs)\n",
    "            \n",
    "            # +++ loss\n",
    "            labels = torch.cat(tuple(batch['label']), dim = 0).to(_device)\n",
    "            batch_loss = loss_function(output, labels)\n",
    "\n",
    "            # +++ backpropagation\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # +++ evaluation\n",
    "            _, preds = torch.max(torch.nn.functional.softmax(output, dim = 1), dim = 1)\n",
    "            train_loss += batch_loss.data * inputs.shape[0]\n",
    "            train_match += torch.sum(preds.data == labels.data)\n",
    "\n",
    "        print('+++ epoch {:3d}, {:6.4f}s Train- Loss: {:.4f} Acc: {:.4f}'.format(epoch, (time.time() -start_time), train_loss.item() /_maDataset.__len__(), train_match.item() /_maDataset.__len__()), end = '')\n",
    "        \n",
    "        #\n",
    "except BaseException as err:    \n",
    "    print(f\"+++ batch_inference() {type(err).__name__}, {err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c1feb",
   "metadata": {},
   "source": [
    "### 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b4442-033c-4534-ad81-e48e9cff03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(preds)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74491a20-505c-4f94-9659-9e6ae0a8dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.merge(_maDataset.df, df_pred, how = 'inner', on = 'img_fName')\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97572b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.groupby('class_label').pred_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa35fe-e1b9-477c-8ef9-5f62cd705e48",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d324e-6e39-4b21-96ca-1aef08264a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 3, figsize = (15, 7), sharey = True)\n",
    "for i, norm in enumerate([None, 'true', 'pred']):\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        df_.class_label,\n",
    "        df_.pred_label,\n",
    "        normalize = norm,\n",
    "        ax = axs[i],\n",
    "        display_labels = ['??', 'aeg', 'alb', 'ano', 'clx', 'cul', 'j/k'],\n",
    "        cmap = 'GnBu',\n",
    "        colorbar = None\n",
    "    )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63202458-c4df-4b3a-805f-36fe64359755",
   "metadata": {},
   "outputs": [],
   "source": [
    "avrgs = ['macro', 'micro', 'weighted']\n",
    "pd.DataFrame([prf(df_.class_label, df_.pred_label, average = mode, zero_division = 0)[:3] for mode in avrgs], columns = ['precision', 'recall', 'f-score'], index = avrgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b6cd2-f2ba-4587-96e7-6261bb4dc34f",
   "metadata": {},
   "source": [
    "#### check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c40f3-002c-41f4-a0b9-74b5f719a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0b5e8-44a8-4ba4-83af-85eafa77a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "row = df_.iloc[i]\n",
    "pilImg = Image.open('%s/%s' %(_imgRoot, row.img_fName))\n",
    "imgdrw = ImageDraw.Draw(pilImg)\n",
    "imgdrw.rectangle([(row.bbx_xtl, row.bbx_ytl), (row.bbx_xbr, row.bbx_ybr)], outline = 'blue', width = 2)\n",
    "plt.imshow(pilImg)\n",
    "plt.axis('off');\n",
    "print('+++%3d %s - %s / %s' %(i, row.img_fName, row.class_label, row.pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = df_[df_.pred_label == '??']\n",
    "len(chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "j += 1\n",
    "row = chk.iloc[j]\n",
    "pilImg = Image.open('%s/%s' %(_imgRoot, row.img_fName))\n",
    "imgdrw = ImageDraw.Draw(pilImg)\n",
    "imgdrw.rectangle([(row.bbx_xtl, row.bbx_ytl), (row.bbx_xbr, row.bbx_ybr)], outline = 'blue', width = 8)\n",
    "plt.imshow(pilImg)\n",
    "plt.axis('off');\n",
    "print('+++%3d - %s / %s' %(i, row.class_label, row.pred_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
