{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6240b6c4",
   "metadata": {},
   "source": [
    "## Ã‰s igual que el 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a2f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 17:00:05.355477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6858de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a59e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_encoder_hparams_and_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d86d5a",
   "metadata": {},
   "source": [
    "### load model: \n",
    "- ***encoder***\n",
    "- ***hyperparameters***\n",
    "- ***parameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c097763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = '124M'\n",
    "n_tokens_to_generate = 40\n",
    "encoder, hparams, params = load_encoder_hparams_and_params(model_size, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294770ba",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad564d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8366e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = '''\n",
    "{\n",
    "  \"n_vocab\": 50257, # number of tokens in our vocabulary\n",
    "  \"n_ctx\": 1024, # maximum possible sequence length of the input\n",
    "  \"n_embd\": 768, # embedding dimension (determines the \"width\" of the network)\n",
    "  \"n_head\": 12, # number of attention heads (n_embd must be divisible by n_head)\n",
    "  \"n_layer\": 12 # number of layers (determines the \"depth\" of the network)\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3060b",
   "metadata": {},
   "source": [
    " ### Main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb536a8",
   "metadata": {},
   "source": [
    "#### input encoding (tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0733cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'what is your favorite musical band?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7f469f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10919, 318, 534, 4004, 10530, 4097, 30]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = encoder.encode(prompt)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb64763",
   "metadata": {},
   "source": [
    "#### output generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1984583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate(inputs, params, n_head, n_tokens_to_generate):\n",
    "\n",
    "    for _ in range(n_tokens_to_generate):\n",
    "        \n",
    "        logits = gpt2.gpt2(inputs, **params, n_head=n_head)  # model forward pass\n",
    "        next_id = gpt2.np.argmax(logits[-1])                 # greedy sampling\n",
    "        inputs.append(int(next_id))                     # append prediction to input\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d94422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10919, 318, 534, 4004, 10530, 4097, 30],\n",
       " [198, 198, 40, 1842, 262, 2647, 286, 262, 44249, 5542, 13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens_to_generate = 11\n",
    "output_ids = _generate(input_ids, params, hparams['n_head'], n_tokens_to_generate)\n",
    "output_ids[:-n_tokens_to_generate], output_ids[-n_tokens_to_generate:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05744b",
   "metadata": {},
   "source": [
    "#### output decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3139ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is your favorite musical band?\n",
      "\n",
      "I love the music of the Grateful Dead.\n"
     ]
    }
   ],
   "source": [
    "print(encoder.decode(output_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fdf29",
   "metadata": {},
   "source": [
    "### Autoregressive generation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "245652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_decode(inputs, params, n_head, n_tokens_to_generate):\n",
    "\n",
    "    print(inputs)\n",
    "    print(encoder.decode(inputs))\n",
    "    print()\n",
    "    \n",
    "    outputs = []\n",
    "    for _ in range(n_tokens_to_generate):\n",
    "        \n",
    "        logits = gpt2.gpt2(inputs, **params, n_head=n_head)  # model forward pass\n",
    "        next_id = gpt2.np.argmax(logits[-1])                       # greedy sampling\n",
    "        \n",
    "        inputs.append(int(next_id))                           # append prediction to input\n",
    "        outputs.append(int(next_id))                          # append prediction to output\n",
    "\n",
    "        # current input/output\n",
    "        print(inputs)\n",
    "        print(encoder.decode(outputs))\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f0827be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10919, 318, 534, 4004, 10530, 4097, 30]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = encoder.encode(prompt)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b69d60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10919, 318, 534, 4004, 10530, 4097, 30, 198, 198, 40]\n",
      "what is your favorite musical band?\n",
      "\n",
      "I\n",
      "\n",
      "[10919, 318, 534, 4004, 10530, 4097, 30, 198, 198, 40, 1842]\n",
      " love\n"
     ]
    }
   ],
   "source": [
    "n_tokens_to_generate = 1\n",
    "output_ids = _generate_decode(input_ids, params, hparams['n_head'], n_tokens_to_generate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
