{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a2f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 16:57:19.273041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6858de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt2\n",
    "from utils import load_encoder_hparams_and_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d86d5a",
   "metadata": {},
   "source": [
    "### load model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c097763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = '124M'# 355M, 774M, 1558M\n",
    "n_tokens_to_generate = 12\n",
    "encoder, hparams, params = load_encoder_hparams_and_params(model_size, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28721a",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10655a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb536a8",
   "metadata": {},
   "source": [
    "### parameters (nested JSON dictionary with trained weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdec91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blocks', 'ln_f', 'wpe', 'wte']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in params.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2bcbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = '''\n",
    "{\n",
    "    \"wpe\": [n_ctx, n_embd],\n",
    "    \"wte\": [n_vocab, n_embd],\n",
    "    \"ln_f\": {\"b\": [n_embd], \"g\": [n_embd]},\n",
    "    \"blocks\": [\n",
    "        {\n",
    "            \"attn\": {\n",
    "                \"c_attn\": {\"b\": [3*n_embd], \"w\": [n_embd, 3*n_embd]},\n",
    "                \"c_proj\": {\"b\": [n_embd], \"w\": [n_embd, n_embd]},\n",
    "            },\n",
    "            \"ln_1\": {\"b\": [n_embd], \"g\": [n_embd]},\n",
    "            \"ln_2\": {\"b\": [n_embd], \"g\": [n_embd]},\n",
    "            \"mlp\": {\n",
    "                \"c_fc\": {\"b\": [4*n_embd], \"w\": [n_embd, 4*n_embd]},\n",
    "                \"c_proj\": {\"b\": [n_embd], \"w\": [4*n_embd, n_embd]},\n",
    "            },\n",
    "        },\n",
    "        ... # repeat for n_layers\n",
    "    ]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80ff5d",
   "metadata": {},
   "source": [
    "### GPT2 loop: Autoregressive output generation (generates next word based on current input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11bdea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __generate(inputs, params, n_head, n_tokens_to_generate):\n",
    "\n",
    "    print(inputs)\n",
    "    print(encoder.decode(inputs))\n",
    "    print()\n",
    "    \n",
    "    outputs = []\n",
    "\n",
    "    for _ in range(n_tokens_to_generate):                    # auto-regressive decode loop\n",
    "        \n",
    "        # project input tokens to vector embedding space\n",
    "        x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -> [n_seq, n_embd]\n",
    "\n",
    "        # forward pass through n_layer transformer blocks\n",
    "        for block in blocks:\n",
    "            x = gpt2.transformer_block(x, **block, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
    "\n",
    "        # reproject output vector to token space\n",
    "        x = gpt2.layer_norm(x, **ln_f)\n",
    "        logits = x @ wte.T \n",
    "        \n",
    "        next_ids = gpt2.np.argmax(logits[-1:])               # get two most likely next tokens\n",
    "        print(next_ids)\n",
    "        print(encoder.decode([next_ids]))\n",
    "\n",
    "        next_id = gpt2.np.argmax(logits[-1])                 # greedy sampling\n",
    "        inputs.append(int(next_id))                          # append prediction to input\n",
    "\n",
    "    return inputs[len(inputs) - n_tokens_to_generate :]      # only return generated ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7684e",
   "metadata": {},
   "source": [
    "### 1. input tokenization: words to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6ed196",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'what is your favorite musical band?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c81a233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = encoder.encode(prompt)\n",
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d624af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10919, 'what')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0], encoder.decode(inputs[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04324d",
   "metadata": {},
   "source": [
    "### 2. input embedding: tokens to vectors\n",
    "- 50257: llargada del diccionari que tenim.\n",
    "- 768: dimensions del embedding.\n",
    "- estructura en la que si li pasem el input 0 \"what\" el busca al diccionari, aquest token li correspon a aquest vector.\n",
    "- si es una paraula que no tenim, intenta fer cosetes com mirar per lletres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375bafc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50257, 768), (1024, 768))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wte'].shape, params['wpe'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177cbd21",
   "metadata": {},
   "source": [
    "#### token embedding space is learned on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd4bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = params['wte'] # token embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec5a9eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00742554, -0.0905292 ,  0.09560295, -0.07777912, -0.04478046],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each token corresponds to a vector in the token embedding space\n",
    "wte[inputs[0]][:5] # show only first 5 components (out of n_embd dimensions = 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff78db",
   "metadata": {},
   "source": [
    "#### position embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f43e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpe = params['wpe'] # position embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f7ca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01882072, -0.1974186 ,  0.00402672,  0.01134686,  0.06382412],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each position, from 0 to n_ctx (max input length), corresponds to a vector in the position embedding space\n",
    "wpe[0][:5] # show only first 5 components (out of n_embd dimensions = 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed0833c",
   "metadata": {},
   "source": [
    "- cada posició ja te un vector en concret i una paraula també té un vector. Llavors, si la paraula x està en x posició, es farà la combinació dels dos vectors. \n",
    "- els vectors de les posicions, venen donats per mirar quina paraula hi havia en cada poscició quan l'hem entrenat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efac78",
   "metadata": {},
   "source": [
    "#### each input token is converted into a vector combining the token vector and the position vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "629ec743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wte[inputs] + wpe[range(len(inputs))]\n",
    "x.shape # embedding vector components: len(inputs) *embedding_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3c2399f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01139518, -0.2879478 ,  0.09962968, -0.06643226,  0.01904366],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8791609b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01139518, -0.2879478 ,  0.09962968, -0.06643226,  0.01904366],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wte[inputs[0]] +wpe[0])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1de7b",
   "metadata": {},
   "source": [
    "### 3. forward pass through transformer blocks (next notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e98ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = params['blocks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1fde6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8682625   0.40907443 -0.7032808  -0.5987273   0.14790252]\n",
      "[-0.75784254  0.482823   -0.13060603 -0.2809174  -0.10698892]\n",
      "[-0.62990224  0.17336455 -0.1549139  -0.09451213 -0.02711199]\n",
      "[-0.6165827   0.16350532 -0.06441966 -0.09630389  0.12699506]\n",
      "[-0.7666638   0.04476391 -0.122725   -0.1490272   0.13410892]\n",
      "[-0.7719635  -0.0340901  -0.08117952 -0.17332554  0.34843472]\n",
      "[-0.86027086 -0.03359476 -0.03841237 -0.25495803  0.5139295 ]\n",
      "[-0.90539     0.07989773 -0.12868711 -0.4138459   0.61734265]\n",
      "[-0.87388366  0.15727827 -0.14486846 -0.4829519   0.57969224]\n",
      "[-0.9719106   0.2692914  -0.36979988 -0.5350647   0.6047204 ]\n",
      "[-1.116415    0.4122141  -0.720613   -0.50802207  0.5594149 ]\n",
      "[-1.5974737  1.0517974 -1.7663152  0.9150096 -0.4267251]\n"
     ]
    }
   ],
   "source": [
    "for block in blocks:\n",
    "    x = gpt2.transformer_block(x, **block, n_head = hparams['n_head'])\n",
    "    print(x[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f4b09",
   "metadata": {},
   "source": [
    "### 4. reproject to token space: vectors to tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ea10f",
   "metadata": {},
   "source": [
    "#### vector normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "919059ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_f = params['ln_f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081ba044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = gpt2.layer_norm(x, **ln_f)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e86a7",
   "metadata": {},
   "source": [
    "#### find the next token: reproject the output vector to the token space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c0c274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 50257), (50257,), 198)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = x @ wte.T\n",
    "logits.shape, logits[-1].shape, gpt2.np.argmax(logits[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbe32eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_last = x[-1] @ wte.T\n",
    "gpt2.np.argmax(logits_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4815c3",
   "metadata": {},
   "source": [
    "### check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "771fd34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = encoder.encode(prompt)\n",
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fc3776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10919, 318, 534, 4004, 10530, 4097, 30]\n",
      "what is your favorite musical band?\n",
      "\n",
      "198\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[198]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens_to_generate = 1\n",
    "__generate(inputs, params, hparams['n_head'], n_tokens_to_generate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
